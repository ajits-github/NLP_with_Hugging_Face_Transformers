{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4f948d7",
      "metadata": {
        "scrolled": true,
        "id": "a4f948d7",
        "outputId": "7be3f38e-0bb3-4fb4-d0a0-d5c349120850"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/anaconda3/envs/transformers-2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "\n",
        "#Set to avoid warning messages.\n",
        "transformers.logging.set_verbosity_error()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80eca074",
      "metadata": {
        "id": "80eca074"
      },
      "source": [
        "## 04.02. Loading a Hugging Face Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18a6b809",
      "metadata": {
        "id": "18a6b809",
        "outputId": "d0c8e53b-30f4-4c23-c9cd-396f00f3b8af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset poem_sentiment (/Users/linkedin/.cache/huggingface/datasets/poem_sentiment/default/1.0.0/4e44428256d42cdde0be6b3db1baa587195e91847adabf976e4f9454f6a82099)\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 438.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'verse_text', 'label'],\n",
            "        num_rows: 892\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'verse_text', 'label'],\n",
            "        num_rows: 105\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['id', 'verse_text', 'label'],\n",
            "        num_rows: 104\n",
            "    })\n",
            "})\n",
            "{'id': [20, 21, 22, 23, 24], 'verse_text': [\"as o'er the earth it wanders wide,\", 'how hearts were answering to his own,', 'glad on its stone-built hearth; and thorough the wide-mouthed smoke-flue', 'sees the clouds reel and roll above our head,', '’tis to behold his vengeance for my son.'], 'label': [2, 1, 2, 2, 0]}\n",
            "\n",
            "Sentiment Labels used ['negative', 'positive', 'no_impact', 'mixed']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "#Use pretrained model checkpoint from Huggingface\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "#Use pre-labeled dataset from huggingface\n",
        "dataset_name= \"poem_sentiment\"\n",
        "\n",
        "poem_sentiments = load_dataset(dataset_name)\n",
        "\n",
        "#Apache Arrow format\n",
        "print(poem_sentiments)\n",
        "print(poem_sentiments[\"test\"][20:25])\n",
        "\n",
        "print(\"\\nSentiment Labels used\",\n",
        "      poem_sentiments[\"train\"].features.get(\"label\").names)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54018a23",
      "metadata": {
        "id": "54018a23"
      },
      "source": [
        "## 04.03. Encoding and pre-processing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb057a9e",
      "metadata": {
        "scrolled": true,
        "id": "eb057a9e",
        "outputId": "1b818778-7a55-4b63-ecf3-45661a56f051"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading cached processed dataset at /Users/linkedin/.cache/huggingface/datasets/poem_sentiment/default/1.0.0/4e44428256d42cdde0be6b3db1baa587195e91847adabf976e4f9454f6a82099/cache-e80e4ec2cbfe3b03.arrow\n",
            "Loading cached processed dataset at /Users/linkedin/.cache/huggingface/datasets/poem_sentiment/default/1.0.0/4e44428256d42cdde0be6b3db1baa587195e91847adabf976e4f9454f6a82099/cache-781d7903f5c80b58.arrow\n",
            "Loading cached processed dataset at /Users/linkedin/.cache/huggingface/datasets/poem_sentiment/default/1.0.0/4e44428256d42cdde0be6b3db1baa587195e91847adabf976e4f9454f6a82099/cache-826927031abc85e4.arrow\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'id': [0, 1, 2, 3, 4], 'verse_text': ['with pale blue berries. in these peaceful shades--', 'it flows so long as falls the rain,', 'and that is why, the lonesome day,', 'when i peruse the conquered fame of heroes, and the victories of mighty generals, i do not envy the generals,', 'of inward strife for truth and liberty.'], 'label': [1, 2, 0, 3, 3], 'input_ids': [[101, 2007, 5122, 2630, 22681, 1012, 1999, 2122, 9379, 13178, 1011, 1011, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2009, 6223, 2061, 2146, 2004, 4212, 1996, 4542, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 2008, 2003, 2339, 1010, 1996, 10459, 14045, 2154, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2043, 1045, 7304, 3366, 1996, 11438, 4476, 1997, 7348, 1010, 1998, 1996, 9248, 1997, 10478, 11593, 1010, 1045, 2079, 2025, 21103, 1996, 11593, 1010, 102, 0, 0], [101, 1997, 20546, 27865, 2005, 3606, 1998, 7044, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}\n"
          ]
        }
      ],
      "source": [
        "#Encoding text\n",
        "\n",
        "from transformers import DistilBertTokenizer\n",
        "\n",
        "db_tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def tokenize(batch):\n",
        "    return db_tokenizer(batch[\"verse_text\"],\n",
        "                        padding=True,\n",
        "                        truncation=True)\n",
        "\n",
        "enc_poem_sentiment = poem_sentiments.map(\n",
        "                        tokenize,\n",
        "                        batched=True,\n",
        "                        batch_size=None)\n",
        "\n",
        "print(enc_poem_sentiment[\"train\"][0:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5775b7cd",
      "metadata": {
        "scrolled": true,
        "id": "5775b7cd",
        "outputId": "50ed695c-cceb-4709-9acb-89b9020f60bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text : it flows so long as falls the rain,\n",
            "\n",
            "Input Map : [101, 2009, 6223, 2061, 2146, 2004, 4212, 1996, 4542, 1010, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Attention Mask : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "Total tokens:  28\n",
            "Non Zero tokens:  11\n",
            "Attention = 1:  11\n"
          ]
        }
      ],
      "source": [
        "#Explore input IDs and Attention Mask\n",
        "\n",
        "print(\"Text :\",\n",
        "      enc_poem_sentiment[\"train\"][1].get(\"verse_text\"))\n",
        "print(\"\\nInput Map :\",\n",
        "      enc_poem_sentiment[\"train\"][1].get(\"input_ids\"))\n",
        "print(\"\\nAttention Mask :\",\n",
        "      enc_poem_sentiment[\"train\"][1].get(\"attention_mask\"))\n",
        "\n",
        "print(\"\\nTotal tokens: \",\n",
        "      len(enc_poem_sentiment[\"train\"][1].get(\"input_ids\")))\n",
        "print(\"Non Zero tokens: \",\n",
        "      len(list(filter(\n",
        "        lambda x :x > 0,\n",
        "          enc_poem_sentiment[\"train\"][1].get(\"input_ids\")))))\n",
        "print(\"Attention = 1: \",\n",
        "      len(list(filter(\n",
        "        lambda x :x > 0,\n",
        "          enc_poem_sentiment[\"train\"][1].get(\"attention_mask\")))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4a924c4",
      "metadata": {
        "id": "a4a924c4",
        "outputId": "a3f8ca39-27e5-4fa5-b0c8-b2bc2213f47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Column Names :  ['id', 'verse_text', 'label', 'input_ids', 'attention_mask']\n",
            "\n",
            "Features :  {'id': Value(dtype='int32', id=None), 'verse_text': Value(dtype='string', id=None), 'label': ClassLabel(names=['negative', 'positive', 'no_impact', 'mixed'], id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}\n"
          ]
        }
      ],
      "source": [
        "#Separate training and validation sets\n",
        "training_dataset = enc_poem_sentiment[\"train\"]\n",
        "validation_dataset=enc_poem_sentiment[\"validation\"]\n",
        "\n",
        "print(\"\\nColumn Names : \",training_dataset.column_names)\n",
        "print(\"\\nFeatures : \",training_dataset.features)\n",
        "\n",
        "labels = training_dataset.features.get(\"label\")\n",
        "num_labels=len(labels.names)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}